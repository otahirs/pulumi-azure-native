# coding=utf-8
# *** WARNING: this file was generated by the Pulumi SDK Generator. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from .. import _utilities
from . import outputs
from ._enums import *
from ._inputs import *

__all__ = ['OutputInitArgs', 'Output']

@pulumi.input_type
class OutputInitArgs:
    def __init__(__self__, *,
                 job_name: pulumi.Input[str],
                 resource_group_name: pulumi.Input[str],
                 datasource: Optional[pulumi.Input[Union['AzureDataLakeStoreOutputDataSourceArgs', 'AzureFunctionOutputDataSourceArgs', 'AzureSqlDatabaseOutputDataSourceArgs', 'AzureSynapseOutputDataSourceArgs', 'AzureTableOutputDataSourceArgs', 'BlobOutputDataSourceArgs', 'DocumentDbOutputDataSourceArgs', 'EventHubOutputDataSourceArgs', 'EventHubV2OutputDataSourceArgs', 'GatewayMessageBusOutputDataSourceArgs', 'PowerBIOutputDataSourceArgs', 'ServiceBusQueueOutputDataSourceArgs', 'ServiceBusTopicOutputDataSourceArgs']]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 output_name: Optional[pulumi.Input[str]] = None,
                 serialization: Optional[pulumi.Input[Union['AvroSerializationArgs', 'CsvSerializationArgs', 'JsonSerializationArgs', 'ParquetSerializationArgs']]] = None,
                 size_window: Optional[pulumi.Input[int]] = None,
                 time_window: Optional[pulumi.Input[str]] = None):
        """
        The set of arguments for constructing a Output resource.
        :param pulumi.Input[str] job_name: The name of the streaming job.
        :param pulumi.Input[str] resource_group_name: The name of the resource group. The name is case insensitive.
        :param pulumi.Input[Union['AzureDataLakeStoreOutputDataSourceArgs', 'AzureFunctionOutputDataSourceArgs', 'AzureSqlDatabaseOutputDataSourceArgs', 'AzureSynapseOutputDataSourceArgs', 'AzureTableOutputDataSourceArgs', 'BlobOutputDataSourceArgs', 'DocumentDbOutputDataSourceArgs', 'EventHubOutputDataSourceArgs', 'EventHubV2OutputDataSourceArgs', 'GatewayMessageBusOutputDataSourceArgs', 'PowerBIOutputDataSourceArgs', 'ServiceBusQueueOutputDataSourceArgs', 'ServiceBusTopicOutputDataSourceArgs']] datasource: Describes the data source that output will be written to. Required on PUT (CreateOrReplace) requests.
        :param pulumi.Input[str] name: Resource name
        :param pulumi.Input[str] output_name: The name of the output.
        :param pulumi.Input[Union['AvroSerializationArgs', 'CsvSerializationArgs', 'JsonSerializationArgs', 'ParquetSerializationArgs']] serialization: Describes how data from an input is serialized or how data is serialized when written to an output. Required on PUT (CreateOrReplace) requests.
        :param pulumi.Input[int] size_window: The size window to constrain a Stream Analytics output to.
        :param pulumi.Input[str] time_window: The time frame for filtering Stream Analytics job outputs.
        """
        pulumi.set(__self__, "job_name", job_name)
        pulumi.set(__self__, "resource_group_name", resource_group_name)
        if datasource is not None:
            pulumi.set(__self__, "datasource", datasource)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if output_name is not None:
            pulumi.set(__self__, "output_name", output_name)
        if serialization is not None:
            pulumi.set(__self__, "serialization", serialization)
        if size_window is not None:
            pulumi.set(__self__, "size_window", size_window)
        if time_window is not None:
            pulumi.set(__self__, "time_window", time_window)

    @property
    @pulumi.getter(name="jobName")
    def job_name(self) -> pulumi.Input[str]:
        """
        The name of the streaming job.
        """
        return pulumi.get(self, "job_name")

    @job_name.setter
    def job_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "job_name", value)

    @property
    @pulumi.getter(name="resourceGroupName")
    def resource_group_name(self) -> pulumi.Input[str]:
        """
        The name of the resource group. The name is case insensitive.
        """
        return pulumi.get(self, "resource_group_name")

    @resource_group_name.setter
    def resource_group_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "resource_group_name", value)

    @property
    @pulumi.getter
    def datasource(self) -> Optional[pulumi.Input[Union['AzureDataLakeStoreOutputDataSourceArgs', 'AzureFunctionOutputDataSourceArgs', 'AzureSqlDatabaseOutputDataSourceArgs', 'AzureSynapseOutputDataSourceArgs', 'AzureTableOutputDataSourceArgs', 'BlobOutputDataSourceArgs', 'DocumentDbOutputDataSourceArgs', 'EventHubOutputDataSourceArgs', 'EventHubV2OutputDataSourceArgs', 'GatewayMessageBusOutputDataSourceArgs', 'PowerBIOutputDataSourceArgs', 'ServiceBusQueueOutputDataSourceArgs', 'ServiceBusTopicOutputDataSourceArgs']]]:
        """
        Describes the data source that output will be written to. Required on PUT (CreateOrReplace) requests.
        """
        return pulumi.get(self, "datasource")

    @datasource.setter
    def datasource(self, value: Optional[pulumi.Input[Union['AzureDataLakeStoreOutputDataSourceArgs', 'AzureFunctionOutputDataSourceArgs', 'AzureSqlDatabaseOutputDataSourceArgs', 'AzureSynapseOutputDataSourceArgs', 'AzureTableOutputDataSourceArgs', 'BlobOutputDataSourceArgs', 'DocumentDbOutputDataSourceArgs', 'EventHubOutputDataSourceArgs', 'EventHubV2OutputDataSourceArgs', 'GatewayMessageBusOutputDataSourceArgs', 'PowerBIOutputDataSourceArgs', 'ServiceBusQueueOutputDataSourceArgs', 'ServiceBusTopicOutputDataSourceArgs']]]):
        pulumi.set(self, "datasource", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        Resource name
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter(name="outputName")
    def output_name(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the output.
        """
        return pulumi.get(self, "output_name")

    @output_name.setter
    def output_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "output_name", value)

    @property
    @pulumi.getter
    def serialization(self) -> Optional[pulumi.Input[Union['AvroSerializationArgs', 'CsvSerializationArgs', 'JsonSerializationArgs', 'ParquetSerializationArgs']]]:
        """
        Describes how data from an input is serialized or how data is serialized when written to an output. Required on PUT (CreateOrReplace) requests.
        """
        return pulumi.get(self, "serialization")

    @serialization.setter
    def serialization(self, value: Optional[pulumi.Input[Union['AvroSerializationArgs', 'CsvSerializationArgs', 'JsonSerializationArgs', 'ParquetSerializationArgs']]]):
        pulumi.set(self, "serialization", value)

    @property
    @pulumi.getter(name="sizeWindow")
    def size_window(self) -> Optional[pulumi.Input[int]]:
        """
        The size window to constrain a Stream Analytics output to.
        """
        return pulumi.get(self, "size_window")

    @size_window.setter
    def size_window(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "size_window", value)

    @property
    @pulumi.getter(name="timeWindow")
    def time_window(self) -> Optional[pulumi.Input[str]]:
        """
        The time frame for filtering Stream Analytics job outputs.
        """
        return pulumi.get(self, "time_window")

    @time_window.setter
    def time_window(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "time_window", value)


class Output(pulumi.CustomResource):
    @overload
    def __init__(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 datasource: Optional[pulumi.Input[Union[pulumi.InputType['AzureDataLakeStoreOutputDataSourceArgs'], pulumi.InputType['AzureFunctionOutputDataSourceArgs'], pulumi.InputType['AzureSqlDatabaseOutputDataSourceArgs'], pulumi.InputType['AzureSynapseOutputDataSourceArgs'], pulumi.InputType['AzureTableOutputDataSourceArgs'], pulumi.InputType['BlobOutputDataSourceArgs'], pulumi.InputType['DocumentDbOutputDataSourceArgs'], pulumi.InputType['EventHubOutputDataSourceArgs'], pulumi.InputType['EventHubV2OutputDataSourceArgs'], pulumi.InputType['GatewayMessageBusOutputDataSourceArgs'], pulumi.InputType['PowerBIOutputDataSourceArgs'], pulumi.InputType['ServiceBusQueueOutputDataSourceArgs'], pulumi.InputType['ServiceBusTopicOutputDataSourceArgs']]]] = None,
                 job_name: Optional[pulumi.Input[str]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 output_name: Optional[pulumi.Input[str]] = None,
                 resource_group_name: Optional[pulumi.Input[str]] = None,
                 serialization: Optional[pulumi.Input[Union[pulumi.InputType['AvroSerializationArgs'], pulumi.InputType['CsvSerializationArgs'], pulumi.InputType['JsonSerializationArgs'], pulumi.InputType['ParquetSerializationArgs']]]] = None,
                 size_window: Optional[pulumi.Input[int]] = None,
                 time_window: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        """
        An output object, containing all information associated with the named output. All outputs are contained under a streaming job.
        API Version: 2020-03-01.
        Previous API Version: 2016-03-01. See https://github.com/pulumi/pulumi-azure-native/discussions/TODO for information on migrating from v1 to v2 of the provider.

        ## Example Usage
        ### Create a DocumentDB output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.DocumentDbOutputDataSourceArgs(
                account_id="someAccountId",
                account_key="accountKey==",
                collection_name_pattern="collection",
                database="db01",
                document_id="documentId",
                partition_key="key",
                type="Microsoft.Storage/DocumentDB",
            ),
            job_name="sj2331",
            output_name="output3022",
            resource_group_name="sjrg7983")

        ```
        ### Create a Gateway Message Bus output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.GatewayMessageBusOutputDataSourceArgs(
                topic="EdgeTopic1",
                type="GatewayMessageBus",
            ),
            job_name="sj2331",
            output_name="output3022",
            resource_group_name="sjrg7983")

        ```
        ### Create a Power BI output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.PowerBIOutputDataSourceArgs(
                dataset="someDataset",
                group_id="ac40305e-3e8d-43ac-8161-c33799f43e95",
                group_name="MyPowerBIGroup",
                refresh_token="someRefreshToken==",
                table="someTable",
                token_user_display_name="Bob Smith",
                token_user_principal_name="bobsmith@contoso.com",
                type="PowerBI",
            ),
            job_name="sj2331",
            output_name="output3022",
            resource_group_name="sjrg7983")

        ```
        ### Create a Service Bus Queue output with Avro serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.ServiceBusQueueOutputDataSourceArgs(
                property_columns=[
                    "column1",
                    "column2",
                ],
                queue_name="sdkqueue",
                service_bus_namespace="sdktest",
                shared_access_policy_key="sharedAccessPolicyKey=",
                shared_access_policy_name="RootManageSharedAccessKey",
                system_property_columns={
                    "MessageId": "col3",
                    "PartitionKey": "col4",
                },
                type="Microsoft.ServiceBus/Queue",
            ),
            job_name="sj5095",
            output_name="output3456",
            resource_group_name="sjrg3410",
            serialization=azure_native.streamanalytics.AvroSerializationArgs(
                type="Avro",
            ))

        ```
        ### Create a Service Bus Topic output with CSV serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.ServiceBusTopicOutputDataSourceArgs(
                property_columns=[
                    "column1",
                    "column2",
                ],
                service_bus_namespace="sdktest",
                shared_access_policy_key="sharedAccessPolicyKey=",
                shared_access_policy_name="RootManageSharedAccessKey",
                topic_name="sdktopic",
                type="Microsoft.ServiceBus/Topic",
            ),
            job_name="sj7094",
            output_name="output7886",
            resource_group_name="sjrg6450",
            serialization=azure_native.streamanalytics.CsvSerializationArgs(
                encoding="UTF8",
                field_delimiter=",",
                type="Csv",
            ))

        ```
        ### Create a blob output with CSV serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.BlobOutputDataSourceArgs(
                container="state",
                date_format="yyyy/MM/dd",
                path_pattern="{date}/{time}",
                storage_accounts=[azure_native.streamanalytics.StorageAccountArgs(
                    account_key="accountKey==",
                    account_name="someAccountName",
                )],
                time_format="HH",
                type="Microsoft.Storage/Blob",
            ),
            job_name="sj900",
            output_name="output1623",
            resource_group_name="sjrg5023",
            serialization=azure_native.streamanalytics.CsvSerializationArgs(
                encoding="UTF8",
                field_delimiter=",",
                type="Csv",
            ))

        ```
        ### Create an Azure Data Lake Store output with JSON serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureDataLakeStoreOutputDataSourceArgs(
                account_name="someaccount",
                date_format="yyyy/MM/dd",
                file_path_prefix="{date}/{time}",
                refresh_token="someRefreshToken==",
                tenant_id="cea4e98b-c798-49e7-8c40-4a2b3beb47dd",
                time_format="HH",
                token_user_display_name="Bob Smith",
                token_user_principal_name="bobsmith@contoso.com",
                type="Microsoft.DataLake/Accounts",
            ),
            job_name="sj3310",
            output_name="output5195",
            resource_group_name="sjrg6912",
            serialization=azure_native.streamanalytics.JsonSerializationArgs(
                encoding="UTF8",
                format="Array",
                type="Json",
            ))

        ```
        ### Create an Azure Data Warehouse output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureSynapseOutputDataSourceArgs(
                database="zhayaSQLpool",
                password="password123",
                server="asatestserver",
                table="test2",
                type="Microsoft.Sql/Server/DataWarehouse",
                user="tolladmin",
            ),
            job_name="sjName",
            output_name="dwOutput",
            resource_group_name="sjrg")

        ```
        ### Create an Azure Function output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureFunctionOutputDataSourceArgs(
                function_app_name="functionappforasaautomation",
                function_name="HttpTrigger2",
                max_batch_count=100,
                max_batch_size=256,
                type="Microsoft.AzureFunction",
            ),
            job_name="sjName",
            output_name="azureFunction1",
            resource_group_name="sjrg")

        ```
        ### Create an Azure SQL database output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureSqlDatabaseOutputDataSourceArgs(
                database="someDatabase",
                password="somePassword",
                server="someServer",
                table="someTable",
                type="Microsoft.Sql/Server/Database",
                user="<user>",
            ),
            job_name="sj6458",
            output_name="output1755",
            resource_group_name="sjrg2157")

        ```
        ### Create an Azure Table output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureTableOutputDataSourceArgs(
                account_key="accountKey==",
                account_name="someAccountName",
                batch_size=25,
                columns_to_remove=[
                    "column1",
                    "column2",
                ],
                partition_key="partitionKey",
                row_key="rowKey",
                table="samples",
                type="Microsoft.Storage/Table",
            ),
            job_name="sj2790",
            output_name="output958",
            resource_group_name="sjrg5176")

        ```
        ### Create an Event Hub output with JSON serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.EventHubOutputDataSourceArgs(
                event_hub_name="sdkeventhub",
                partition_key="partitionKey",
                service_bus_namespace="sdktest",
                shared_access_policy_key="sharedAccessPolicyKey=",
                shared_access_policy_name="RootManageSharedAccessKey",
                type="Microsoft.ServiceBus/EventHub",
            ),
            job_name="sj3310",
            output_name="output5195",
            resource_group_name="sjrg6912",
            serialization=azure_native.streamanalytics.JsonSerializationArgs(
                encoding="UTF8",
                format="Array",
                type="Json",
            ))

        ```

        ## Import

        An existing resource can be imported using its type token, name, and identifier, e.g.

        ```sh
        $ pulumi import azure-native:streamanalytics:Output output5195 /subscriptions/56b5e0a9-b645-407d-99b0-c64f86013e3d/resourceGroups/sjrg6912/providers/Microsoft.StreamAnalytics/streamingjobs/sj3310/outputs/output5195 
        ```

        :param str resource_name: The name of the resource.
        :param pulumi.ResourceOptions opts: Options for the resource.
        :param pulumi.Input[Union[pulumi.InputType['AzureDataLakeStoreOutputDataSourceArgs'], pulumi.InputType['AzureFunctionOutputDataSourceArgs'], pulumi.InputType['AzureSqlDatabaseOutputDataSourceArgs'], pulumi.InputType['AzureSynapseOutputDataSourceArgs'], pulumi.InputType['AzureTableOutputDataSourceArgs'], pulumi.InputType['BlobOutputDataSourceArgs'], pulumi.InputType['DocumentDbOutputDataSourceArgs'], pulumi.InputType['EventHubOutputDataSourceArgs'], pulumi.InputType['EventHubV2OutputDataSourceArgs'], pulumi.InputType['GatewayMessageBusOutputDataSourceArgs'], pulumi.InputType['PowerBIOutputDataSourceArgs'], pulumi.InputType['ServiceBusQueueOutputDataSourceArgs'], pulumi.InputType['ServiceBusTopicOutputDataSourceArgs']]] datasource: Describes the data source that output will be written to. Required on PUT (CreateOrReplace) requests.
        :param pulumi.Input[str] job_name: The name of the streaming job.
        :param pulumi.Input[str] name: Resource name
        :param pulumi.Input[str] output_name: The name of the output.
        :param pulumi.Input[str] resource_group_name: The name of the resource group. The name is case insensitive.
        :param pulumi.Input[Union[pulumi.InputType['AvroSerializationArgs'], pulumi.InputType['CsvSerializationArgs'], pulumi.InputType['JsonSerializationArgs'], pulumi.InputType['ParquetSerializationArgs']]] serialization: Describes how data from an input is serialized or how data is serialized when written to an output. Required on PUT (CreateOrReplace) requests.
        :param pulumi.Input[int] size_window: The size window to constrain a Stream Analytics output to.
        :param pulumi.Input[str] time_window: The time frame for filtering Stream Analytics job outputs.
        """
        ...
    @overload
    def __init__(__self__,
                 resource_name: str,
                 args: OutputInitArgs,
                 opts: Optional[pulumi.ResourceOptions] = None):
        """
        An output object, containing all information associated with the named output. All outputs are contained under a streaming job.
        API Version: 2020-03-01.
        Previous API Version: 2016-03-01. See https://github.com/pulumi/pulumi-azure-native/discussions/TODO for information on migrating from v1 to v2 of the provider.

        ## Example Usage
        ### Create a DocumentDB output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.DocumentDbOutputDataSourceArgs(
                account_id="someAccountId",
                account_key="accountKey==",
                collection_name_pattern="collection",
                database="db01",
                document_id="documentId",
                partition_key="key",
                type="Microsoft.Storage/DocumentDB",
            ),
            job_name="sj2331",
            output_name="output3022",
            resource_group_name="sjrg7983")

        ```
        ### Create a Gateway Message Bus output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.GatewayMessageBusOutputDataSourceArgs(
                topic="EdgeTopic1",
                type="GatewayMessageBus",
            ),
            job_name="sj2331",
            output_name="output3022",
            resource_group_name="sjrg7983")

        ```
        ### Create a Power BI output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.PowerBIOutputDataSourceArgs(
                dataset="someDataset",
                group_id="ac40305e-3e8d-43ac-8161-c33799f43e95",
                group_name="MyPowerBIGroup",
                refresh_token="someRefreshToken==",
                table="someTable",
                token_user_display_name="Bob Smith",
                token_user_principal_name="bobsmith@contoso.com",
                type="PowerBI",
            ),
            job_name="sj2331",
            output_name="output3022",
            resource_group_name="sjrg7983")

        ```
        ### Create a Service Bus Queue output with Avro serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.ServiceBusQueueOutputDataSourceArgs(
                property_columns=[
                    "column1",
                    "column2",
                ],
                queue_name="sdkqueue",
                service_bus_namespace="sdktest",
                shared_access_policy_key="sharedAccessPolicyKey=",
                shared_access_policy_name="RootManageSharedAccessKey",
                system_property_columns={
                    "MessageId": "col3",
                    "PartitionKey": "col4",
                },
                type="Microsoft.ServiceBus/Queue",
            ),
            job_name="sj5095",
            output_name="output3456",
            resource_group_name="sjrg3410",
            serialization=azure_native.streamanalytics.AvroSerializationArgs(
                type="Avro",
            ))

        ```
        ### Create a Service Bus Topic output with CSV serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.ServiceBusTopicOutputDataSourceArgs(
                property_columns=[
                    "column1",
                    "column2",
                ],
                service_bus_namespace="sdktest",
                shared_access_policy_key="sharedAccessPolicyKey=",
                shared_access_policy_name="RootManageSharedAccessKey",
                topic_name="sdktopic",
                type="Microsoft.ServiceBus/Topic",
            ),
            job_name="sj7094",
            output_name="output7886",
            resource_group_name="sjrg6450",
            serialization=azure_native.streamanalytics.CsvSerializationArgs(
                encoding="UTF8",
                field_delimiter=",",
                type="Csv",
            ))

        ```
        ### Create a blob output with CSV serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.BlobOutputDataSourceArgs(
                container="state",
                date_format="yyyy/MM/dd",
                path_pattern="{date}/{time}",
                storage_accounts=[azure_native.streamanalytics.StorageAccountArgs(
                    account_key="accountKey==",
                    account_name="someAccountName",
                )],
                time_format="HH",
                type="Microsoft.Storage/Blob",
            ),
            job_name="sj900",
            output_name="output1623",
            resource_group_name="sjrg5023",
            serialization=azure_native.streamanalytics.CsvSerializationArgs(
                encoding="UTF8",
                field_delimiter=",",
                type="Csv",
            ))

        ```
        ### Create an Azure Data Lake Store output with JSON serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureDataLakeStoreOutputDataSourceArgs(
                account_name="someaccount",
                date_format="yyyy/MM/dd",
                file_path_prefix="{date}/{time}",
                refresh_token="someRefreshToken==",
                tenant_id="cea4e98b-c798-49e7-8c40-4a2b3beb47dd",
                time_format="HH",
                token_user_display_name="Bob Smith",
                token_user_principal_name="bobsmith@contoso.com",
                type="Microsoft.DataLake/Accounts",
            ),
            job_name="sj3310",
            output_name="output5195",
            resource_group_name="sjrg6912",
            serialization=azure_native.streamanalytics.JsonSerializationArgs(
                encoding="UTF8",
                format="Array",
                type="Json",
            ))

        ```
        ### Create an Azure Data Warehouse output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureSynapseOutputDataSourceArgs(
                database="zhayaSQLpool",
                password="password123",
                server="asatestserver",
                table="test2",
                type="Microsoft.Sql/Server/DataWarehouse",
                user="tolladmin",
            ),
            job_name="sjName",
            output_name="dwOutput",
            resource_group_name="sjrg")

        ```
        ### Create an Azure Function output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureFunctionOutputDataSourceArgs(
                function_app_name="functionappforasaautomation",
                function_name="HttpTrigger2",
                max_batch_count=100,
                max_batch_size=256,
                type="Microsoft.AzureFunction",
            ),
            job_name="sjName",
            output_name="azureFunction1",
            resource_group_name="sjrg")

        ```
        ### Create an Azure SQL database output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureSqlDatabaseOutputDataSourceArgs(
                database="someDatabase",
                password="somePassword",
                server="someServer",
                table="someTable",
                type="Microsoft.Sql/Server/Database",
                user="<user>",
            ),
            job_name="sj6458",
            output_name="output1755",
            resource_group_name="sjrg2157")

        ```
        ### Create an Azure Table output

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.AzureTableOutputDataSourceArgs(
                account_key="accountKey==",
                account_name="someAccountName",
                batch_size=25,
                columns_to_remove=[
                    "column1",
                    "column2",
                ],
                partition_key="partitionKey",
                row_key="rowKey",
                table="samples",
                type="Microsoft.Storage/Table",
            ),
            job_name="sj2790",
            output_name="output958",
            resource_group_name="sjrg5176")

        ```
        ### Create an Event Hub output with JSON serialization

        ```python
        import pulumi
        import pulumi_azure_native as azure_native

        output = azure_native.streamanalytics.Output("output",
            datasource=azure_native.streamanalytics.EventHubOutputDataSourceArgs(
                event_hub_name="sdkeventhub",
                partition_key="partitionKey",
                service_bus_namespace="sdktest",
                shared_access_policy_key="sharedAccessPolicyKey=",
                shared_access_policy_name="RootManageSharedAccessKey",
                type="Microsoft.ServiceBus/EventHub",
            ),
            job_name="sj3310",
            output_name="output5195",
            resource_group_name="sjrg6912",
            serialization=azure_native.streamanalytics.JsonSerializationArgs(
                encoding="UTF8",
                format="Array",
                type="Json",
            ))

        ```

        ## Import

        An existing resource can be imported using its type token, name, and identifier, e.g.

        ```sh
        $ pulumi import azure-native:streamanalytics:Output output5195 /subscriptions/56b5e0a9-b645-407d-99b0-c64f86013e3d/resourceGroups/sjrg6912/providers/Microsoft.StreamAnalytics/streamingjobs/sj3310/outputs/output5195 
        ```

        :param str resource_name: The name of the resource.
        :param OutputInitArgs args: The arguments to use to populate this resource's properties.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        ...
    def __init__(__self__, resource_name: str, *args, **kwargs):
        resource_args, opts = _utilities.get_resource_args_opts(OutputInitArgs, pulumi.ResourceOptions, *args, **kwargs)
        if resource_args is not None:
            __self__._internal_init(resource_name, opts, **resource_args.__dict__)
        else:
            __self__._internal_init(resource_name, *args, **kwargs)

    def _internal_init(__self__,
                 resource_name: str,
                 opts: Optional[pulumi.ResourceOptions] = None,
                 datasource: Optional[pulumi.Input[Union[pulumi.InputType['AzureDataLakeStoreOutputDataSourceArgs'], pulumi.InputType['AzureFunctionOutputDataSourceArgs'], pulumi.InputType['AzureSqlDatabaseOutputDataSourceArgs'], pulumi.InputType['AzureSynapseOutputDataSourceArgs'], pulumi.InputType['AzureTableOutputDataSourceArgs'], pulumi.InputType['BlobOutputDataSourceArgs'], pulumi.InputType['DocumentDbOutputDataSourceArgs'], pulumi.InputType['EventHubOutputDataSourceArgs'], pulumi.InputType['EventHubV2OutputDataSourceArgs'], pulumi.InputType['GatewayMessageBusOutputDataSourceArgs'], pulumi.InputType['PowerBIOutputDataSourceArgs'], pulumi.InputType['ServiceBusQueueOutputDataSourceArgs'], pulumi.InputType['ServiceBusTopicOutputDataSourceArgs']]]] = None,
                 job_name: Optional[pulumi.Input[str]] = None,
                 name: Optional[pulumi.Input[str]] = None,
                 output_name: Optional[pulumi.Input[str]] = None,
                 resource_group_name: Optional[pulumi.Input[str]] = None,
                 serialization: Optional[pulumi.Input[Union[pulumi.InputType['AvroSerializationArgs'], pulumi.InputType['CsvSerializationArgs'], pulumi.InputType['JsonSerializationArgs'], pulumi.InputType['ParquetSerializationArgs']]]] = None,
                 size_window: Optional[pulumi.Input[int]] = None,
                 time_window: Optional[pulumi.Input[str]] = None,
                 __props__=None):
        opts = pulumi.ResourceOptions.merge(_utilities.get_resource_opts_defaults(), opts)
        if not isinstance(opts, pulumi.ResourceOptions):
            raise TypeError('Expected resource options to be a ResourceOptions instance')
        if opts.id is None:
            if __props__ is not None:
                raise TypeError('__props__ is only valid when passed in combination with a valid opts.id to get an existing resource')
            __props__ = OutputInitArgs.__new__(OutputInitArgs)

            __props__.__dict__["datasource"] = datasource
            if job_name is None and not opts.urn:
                raise TypeError("Missing required property 'job_name'")
            __props__.__dict__["job_name"] = job_name
            __props__.__dict__["name"] = name
            __props__.__dict__["output_name"] = output_name
            if resource_group_name is None and not opts.urn:
                raise TypeError("Missing required property 'resource_group_name'")
            __props__.__dict__["resource_group_name"] = resource_group_name
            __props__.__dict__["serialization"] = serialization
            __props__.__dict__["size_window"] = size_window
            __props__.__dict__["time_window"] = time_window
            __props__.__dict__["diagnostics"] = None
            __props__.__dict__["etag"] = None
            __props__.__dict__["type"] = None
        alias_opts = pulumi.ResourceOptions(aliases=[pulumi.Alias(type_="azure-native:streamanalytics/v20160301:Output"), pulumi.Alias(type_="azure-native:streamanalytics/v20170401preview:Output"), pulumi.Alias(type_="azure-native:streamanalytics/v20200301:Output"), pulumi.Alias(type_="azure-native:streamanalytics/v20211001preview:Output")])
        opts = pulumi.ResourceOptions.merge(opts, alias_opts)
        super(Output, __self__).__init__(
            'azure-native:streamanalytics:Output',
            resource_name,
            __props__,
            opts)

    @staticmethod
    def get(resource_name: str,
            id: pulumi.Input[str],
            opts: Optional[pulumi.ResourceOptions] = None) -> 'Output':
        """
        Get an existing Output resource's state with the given name, id, and optional extra
        properties used to qualify the lookup.

        :param str resource_name: The unique name of the resulting resource.
        :param pulumi.Input[str] id: The unique provider ID of the resource to lookup.
        :param pulumi.ResourceOptions opts: Options for the resource.
        """
        opts = pulumi.ResourceOptions.merge(opts, pulumi.ResourceOptions(id=id))

        __props__ = OutputInitArgs.__new__(OutputInitArgs)

        __props__.__dict__["datasource"] = None
        __props__.__dict__["diagnostics"] = None
        __props__.__dict__["etag"] = None
        __props__.__dict__["name"] = None
        __props__.__dict__["serialization"] = None
        __props__.__dict__["size_window"] = None
        __props__.__dict__["time_window"] = None
        __props__.__dict__["type"] = None
        return Output(resource_name, opts=opts, __props__=__props__)

    @property
    @pulumi.getter
    def datasource(self) -> pulumi.Output[Optional[Any]]:
        """
        Describes the data source that output will be written to. Required on PUT (CreateOrReplace) requests.
        """
        return pulumi.get(self, "datasource")

    @property
    @pulumi.getter
    def diagnostics(self) -> pulumi.Output['outputs.DiagnosticsResponse']:
        """
        Describes conditions applicable to the Input, Output, or the job overall, that warrant customer attention.
        """
        return pulumi.get(self, "diagnostics")

    @property
    @pulumi.getter
    def etag(self) -> pulumi.Output[str]:
        """
        The current entity tag for the output. This is an opaque string. You can use it to detect whether the resource has changed between requests. You can also use it in the If-Match or If-None-Match headers for write operations for optimistic concurrency.
        """
        return pulumi.get(self, "etag")

    @property
    @pulumi.getter
    def name(self) -> pulumi.Output[Optional[str]]:
        """
        Resource name
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def serialization(self) -> pulumi.Output[Optional[Any]]:
        """
        Describes how data from an input is serialized or how data is serialized when written to an output. Required on PUT (CreateOrReplace) requests.
        """
        return pulumi.get(self, "serialization")

    @property
    @pulumi.getter(name="sizeWindow")
    def size_window(self) -> pulumi.Output[Optional[int]]:
        """
        The size window to constrain a Stream Analytics output to.
        """
        return pulumi.get(self, "size_window")

    @property
    @pulumi.getter(name="timeWindow")
    def time_window(self) -> pulumi.Output[Optional[str]]:
        """
        The time frame for filtering Stream Analytics job outputs.
        """
        return pulumi.get(self, "time_window")

    @property
    @pulumi.getter
    def type(self) -> pulumi.Output[str]:
        """
        Resource type
        """
        return pulumi.get(self, "type")

